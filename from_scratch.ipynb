{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Celtic Mutations -- From Scratch\n",
    "### Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_file: str = 'data/train.tsv'\n",
    "test_file: str = ''\n",
    "val_split: float = 0.1\n",
    "\n",
    "states: dict = {\n",
    "    'S': 0,\n",
    "    'U': 0,\n",
    "    'T': 0,\n",
    "    'H': 0,\n",
    "    'N': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(file: str) -> list:\n",
    "    print(\"Loading data from file {}...\".format(file))\n",
    "    file = open(file, 'r')\n",
    "    data = []\n",
    "    sentence = []\n",
    "    for line in file:\n",
    "        pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        if pieces[0] == '<S>':\n",
    "            data.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            sentence.append(pieces)\n",
    "    print(\"Loaded {} sentences\".format(len(data)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file data/train.tsv...\n",
      "Loaded 395922 sentences\n",
      "Loading data from file data/train.tsv...\n",
      "Loaded 395922 sentences\n",
      "Splitting data...\n",
      "39593  validation samples\n",
      "356329  training samples\n"
     ]
    }
   ],
   "source": [
    "train_data: list = load_data(train_file)\n",
    "if len(test_file) > 0:\n",
    "    test_data: list = load_data(test_file)\n",
    "print(\"Splitting data...\")\n",
    "num_train_samples: int = int(len(train_data)*(1-val_split))\n",
    "val_data: list = train_data[num_train_samples:]\n",
    "print(len(val_data), \" validation samples\")\n",
    "train_data: list = train_data[:num_train_samples]\n",
    "print(len(train_data), \" training samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_probabilities_from_counts(counts_dict: dict) -> dict:\n",
    "    counts_sum: int = sum(counts_dict.values())\n",
    "    probabilities_dict: dict = {}\n",
    "    for count_id in counts_dict:\n",
    "        count = counts_dict[count_id]\n",
    "        probabilities_dict[count_id] = count / counts_sum\n",
    "    assert round(sum(probabilities_dict.values()), 2) == 1.0, \"All probabilities should sum to 1 but got {}\".format(round(sum(probabilities_dict.values()), 2))\n",
    "    return probabilities_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_max_float_id_from_dict(float_dict: dict) -> str:\n",
    "    max_value: float = -0.1\n",
    "    max_id: float = None\n",
    "    for dict_id in float_dict:\n",
    "        if float_dict[dict_id] > max_value:\n",
    "            max_value = float_dict[dict_id]\n",
    "            max_id = dict_id\n",
    "    return max_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_initial_state_probabilities(data: list) -> dict:\n",
    "    initial_state_counts: dict = states.copy()\n",
    "    for sentence in data:\n",
    "        initial_state: str = sentence[0][1]\n",
    "        if initial_state in initial_state_counts:\n",
    "            initial_state_counts[initial_state] += 1\n",
    "    initial_state_probabilities: dict = compute_probabilities_from_counts(initial_state_counts)\n",
    "    return initial_state_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_transition_state_probabilities(data: list) -> dict:\n",
    "    # create a dictionary with two levels, the first being the previous state and the second being the current state\n",
    "    transition_state_counts: dict = {state: states.copy() for state in states}\n",
    "    for sentence in data:\n",
    "        # since we enumerate over a list that excludes the first item, the enumeration index is one behind\n",
    "        for prev_idx, word in enumerate(sentence[1:]):\n",
    "            prev_state: str = sentence[prev_idx][1]\n",
    "            current_state: str = word[1]\n",
    "            if prev_state in transition_state_counts and current_state in transition_state_counts[prev_state]:\n",
    "                transition_state_counts[prev_state][current_state] += 1\n",
    "    transition_state_probabilities: dict = {state: {} for state in states}\n",
    "    for prev_state in transition_state_counts:\n",
    "        transition_state_probabilities[prev_state] = compute_probabilities_from_counts(transition_state_counts[prev_state])\n",
    "    return transition_state_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_emission_probabilities(data: list) -> dict:\n",
    "    emission_counts_by_state: dict = {state: {} for state in states}\n",
    "    for sentence in data:\n",
    "        for word_state_pair in sentence:\n",
    "            word, state = word_state_pair\n",
    "            if state in emission_counts_by_state:\n",
    "                # initialize word in state dict if the first occurrence of word X in state Y\n",
    "                if word not in emission_counts_by_state[state]:\n",
    "                    emission_counts_by_state[state][word] = 0\n",
    "                emission_counts_by_state[state][word] += 1\n",
    "    emission_probabilities_by_state: dict = {state: {} for state in states}\n",
    "    for state in emission_counts_by_state:\n",
    "        emission_probabilities_by_state[state] = compute_probabilities_from_counts(emission_counts_by_state[state])\n",
    "    return emission_probabilities_by_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, data):\n",
    "        self.initial_state_probabilities, self.transition_probabilities, self.emission_probabilities = self.fit(data)\n",
    "\n",
    "    @staticmethod\n",
    "    def fit(data: list) -> tuple:\n",
    "        initial_state_probabilities = generate_initial_state_probabilities(data)\n",
    "        transition_probabilities = generate_transition_state_probabilities(data)\n",
    "        emission_probabilities = generate_emission_probabilities(data)\n",
    "        return initial_state_probabilities, transition_probabilities, emission_probabilities\n",
    "\n",
    "    def predict(self, sentence: str) -> dict:\n",
    "        words: list = sentence.split(\" \")\n",
    "        state_sequence: list = []\n",
    "        # begin each sentence using initial state probabilities, then switches to transition probabilities\n",
    "        state_probabilities: dict = self.initial_state_probabilities.copy()\n",
    "        for idx, word in enumerate(words):\n",
    "            for state in state_probabilities:\n",
    "                if word in self.emission_probabilities[state]:\n",
    "                    state_probabilities[state] = state_probabilities[state]*self.emission_probabilities[state][word]\n",
    "                else:\n",
    "                    state_probabilities[state] = 0\n",
    "            state_sequence.append(get_max_float_id_from_dict(state_probabilities))\n",
    "            # for next word, initialize probabilities as transition probabilities from the previous state\n",
    "            state_probabilities = self.transition_probabilities[state_sequence[idx]].copy()\n",
    "        return state_sequence\n",
    "\n",
    "    def evaluate(self, sentences: list, labels: list) -> float:\n",
    "        total, correct = 0, 0\n",
    "        for sentence_idx, sentence in enumerate(sentences):\n",
    "            predicted_sequence: list = self.predict(sentence)\n",
    "            total += len(predicted_sequence)\n",
    "            correct += sum([int(predicted == labels[sentence_idx][tag_idx]) for tag_idx, predicted in enumerate(predicted_sequence)])\n",
    "        return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = HMM(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: d'fhan sé ina tost ar feadh scaithimh eile sular labhair sé .\n",
      "Predicted Sequence: ['N', 'N', 'N', 'S', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "Ground Truth Sequence: ['N', 'N', 'N', 'S', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "val_sentence = \" \".join([word[0] for word in val_data[100]])\n",
    "print(\"Sentence:\", val_sentence)\n",
    "print(\"Predicted Sequence:\", model.predict(val_sentence))\n",
    "print(\"Ground Truth Sequence:\", [word[1] for word in val_data[100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: cuairt ar an leabharlann\n",
      "Predicted Sequence: ['N', 'N', 'N', 'N']\n",
      "Ground Truth Sequence: ['N', 'N', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "val_sentence = \" \".join([word[0] for word in val_data[1]])\n",
    "print(\"Sentence:\", val_sentence)\n",
    "print(\"Predicted Sequence:\", model.predict(val_sentence))\n",
    "print(\"Ground Truth Sequence:\", [word[1] for word in val_data[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def format_data(data: list) -> tuple:\n",
    "    sentences: list = []\n",
    "    labels: list = []\n",
    "    for sentence in val_data:\n",
    "        sentences.append((\" \".join(word_state_pair[0] for word_state_pair in sentence)))\n",
    "        labels.append([word_state_pair[1] for word_state_pair in sentence])\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['socraíodh', 'N'], ['go', 'N'], ['raibh', 'N'], ['gá', 'N'], ['lena', 'N'], ['leithéid', 'N'], [',', 'N'], ['mar', 'N'], ['go', 'N'], ['bíonn', 'U'], ['na', 'N']]\n",
      "Validation Accuracy:  89.81%\n"
     ]
    }
   ],
   "source": [
    "val_sentences, val_labels = format_data(val_data)\n",
    "val_acc = model.evaluate(val_sentences, val_labels)\n",
    "print(\"Validation Accuracy: \", str(round(val_acc*100, 2)) + \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  89.81434392455854%\n"
     ]
    }
   ],
   "source": [
    "if \"test_data\" in globals():\n",
    "    test_sentences, test_labels = format_data(test_data)\n",
    "    test_acc = model.evaluate(test_sentences, test_labels)\n",
    "    print(\"Testing Accuracy: \", str(round(test_acc*100, 2)) + \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"test_data\" in globals():\n",
    "    test_sentences, test_labels = format_data(test_data)\n",
    "    test_acc = model.evaluate(test_sentences, test_labels)\n",
    "    print(\"Testing Accuracy: \", str(round(test_acc*100, 2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}