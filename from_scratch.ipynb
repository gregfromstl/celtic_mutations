{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Celtic Mutations -- From Scratch\n",
    "### Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "train_file: str = 'data/train.tsv'\n",
    "test_file: str = ''\n",
    "val_split: float = 0.1\n",
    "\n",
    "states: dict = {\n",
    "    'S': 0,\n",
    "    'U': 0,\n",
    "    'T': 0,\n",
    "    'H': 0,\n",
    "    'N': 0\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def load_data(file: str) -> list:\n",
    "    print(\"Loading data from file {}...\".format(file))\n",
    "    file = open(file, 'r')\n",
    "    data = []\n",
    "    sentence = []\n",
    "    for line in file:\n",
    "        pieces = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "        if pieces[0] == '<S>':\n",
    "            data.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            sentence.append(pieces)\n",
    "    print(\"Loaded {} sentences\".format(len(data)))\n",
    "    return data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from file data/train.tsv...\n",
      "Loaded 395922 sentences\n",
      "Splitting data...\n",
      "39593  validation samples\n",
      "356329  training samples\n"
     ]
    }
   ],
   "source": [
    "train_data: list = load_data('data/train.tsv')\n",
    "if len(test_file) <= 0:\n",
    "    print(\"Splitting data...\")\n",
    "    num_train_samples: int = int(len(train_data)*(1-val_split))\n",
    "    val_data: list = train_data[num_train_samples:]\n",
    "    print(len(val_data), \" validation samples\")\n",
    "    train_data: list = train_data[:num_train_samples]\n",
    "    print(len(train_data), \" training samples\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "def compute_probabilities_from_counts(counts_dict: dict) -> dict:\n",
    "    counts_sum: int = sum(counts_dict.values())\n",
    "    probabilities_dict: dict = {}\n",
    "    for count_id in counts_dict:\n",
    "        count = counts_dict[count_id]\n",
    "        probabilities_dict[count_id] = count / counts_sum\n",
    "    assert round(sum(probabilities_dict.values()), 2) == 1.0, \"All probabilities should sum to 1 but got {}\".format(round(sum(probabilities_dict.values()), 2))\n",
    "    return probabilities_dict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def get_max_float_id_from_dict(float_dict: dict) -> str:\n",
    "    max_value: float = -0.1\n",
    "    max_id: float = None\n",
    "    for dict_id in float_dict:\n",
    "        if float_dict[dict_id] > max_value:\n",
    "            max_value = float_dict[dict_id]\n",
    "            max_id = dict_id\n",
    "    return max_id\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "def generate_initial_state_probabilities(data: list) -> dict:\n",
    "    initial_state_counts: dict = states.copy()\n",
    "    for sentence in data:\n",
    "        initial_state: str = sentence[0][1]\n",
    "        if initial_state in initial_state_counts:\n",
    "            initial_state_counts[initial_state] += 1\n",
    "    initial_state_probabilities: dict = compute_probabilities_from_counts(initial_state_counts)\n",
    "    return initial_state_probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "def generate_transition_state_probabilities(data: list) -> dict:\n",
    "    # create a dictionary with two levels, the first being the previous state and the second being the current state\n",
    "    transition_state_counts: dict = {state: states.copy() for state in states}\n",
    "    for sentence in data:\n",
    "        # since we enumerate over a list that excludes the first item, the enumeration index is one behind\n",
    "        for prev_idx, word in enumerate(sentence[1:]):\n",
    "            prev_state: str = sentence[prev_idx][1]\n",
    "            current_state: str = word[1]\n",
    "            if prev_state in transition_state_counts and current_state in transition_state_counts[prev_state]:\n",
    "                transition_state_counts[prev_state][current_state] += 1\n",
    "    transition_state_probabilities: dict = {state: {} for state in states}\n",
    "    for prev_state in transition_state_counts:\n",
    "        transition_state_probabilities[prev_state] = compute_probabilities_from_counts(transition_state_counts[prev_state])\n",
    "    return transition_state_probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def generate_emission_probabilities(data: list) -> dict:\n",
    "    emission_counts_by_state: dict = {state: {} for state in states}\n",
    "    for sentence in data:\n",
    "        for word_state_pair in sentence:\n",
    "            word, state = word_state_pair\n",
    "            if state in emission_counts_by_state:\n",
    "                # initialize word in state dict if the first occurrence of word X in state Y\n",
    "                if word not in emission_counts_by_state[state]:\n",
    "                    emission_counts_by_state[state][word] = 0\n",
    "                emission_counts_by_state[state][word] += 1\n",
    "    emission_probabilities_by_state: dict = {state: {} for state in states}\n",
    "    for state in emission_counts_by_state:\n",
    "        emission_probabilities_by_state[state] = compute_probabilities_from_counts(emission_counts_by_state[state])\n",
    "    return emission_probabilities_by_state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, data):\n",
    "        self.initial_state_probabilities, self.transition_probabilities, self.emission_probabilities = self.fit(data)\n",
    "\n",
    "    @staticmethod\n",
    "    def fit(data: list) -> tuple:\n",
    "        initial_state_probabilities = generate_initial_state_probabilities(data)\n",
    "        transition_probabilities = generate_transition_state_probabilities(data)\n",
    "        emission_probabilities = generate_emission_probabilities(data)\n",
    "        return initial_state_probabilities, transition_probabilities, emission_probabilities\n",
    "\n",
    "    def predict(self, sentence: str) -> dict:\n",
    "        words: list = sentence.split(\" \")\n",
    "        state_sequence = []\n",
    "        state_probabilities: dict = self.initial_state_probabilities.copy()\n",
    "        for idx, word in enumerate(words):\n",
    "            for state in state_probabilities:\n",
    "                if word in self.emission_probabilities[state]:\n",
    "                    state_probabilities[state] = state_probabilities[state]*self.emission_probabilities[state][word]\n",
    "                else:\n",
    "                    state_probabilities[state] = 0\n",
    "            state_sequence.append(get_max_float_id_from_dict(state_probabilities))\n",
    "            # for next word, initialize probabilities as transition probabilities from the previous state\n",
    "            state_probabilities = self.transition_probabilities[state_sequence[idx]].copy()\n",
    "        return state_sequence\n",
    "\n",
    "    def evaluate(self, sentences: list, labels: list):\n",
    "        total, correct = 0, 0\n",
    "        for sentence_idx, sentence in enumerate(sentences):\n",
    "            predicted_sequence = self.predict(sentence)\n",
    "            total += len(predicted_sequence)\n",
    "            correct += sum([int(predicted == labels[sentence_idx][tag_idx]) for tag_idx, predicted in enumerate(predicted_sequence)])\n",
    "        print(correct / total)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "model = HMM(train_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'N', 'S', 'N', 'N', 'N', 'N', 'N', 'N']\n",
      "['N', 'N', 'U', 'N', 'N', 'N', 'N', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(\" \".join([word[0] for word in val_data[0]])))\n",
    "print([word[1] for word in val_data[0]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N', 'N', 'N', 'N']\n"
     ]
    }
   ],
   "source": [
    "model.predict(\" \".join([word[0] for word in val_data[1]]))\n",
    "print([word[1] for word in val_data[1]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8981434392455854\n"
     ]
    }
   ],
   "source": [
    "val_sentences = []\n",
    "val_labels = []\n",
    "for sentence in val_data:\n",
    "    val_sentences.append((\" \".join(word_state_pair[0] for word_state_pair in sentence)))\n",
    "    val_labels.append([word_state_pair[1] for word_state_pair in sentence])\n",
    "model.evaluate(val_sentences, val_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}