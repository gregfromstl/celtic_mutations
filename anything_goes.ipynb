{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anything Goes Implementation\n",
    "### Bidirectional LSTM for Sequence Tagging\n",
    "\n",
    "For the \"Anything Goes\" implementation I used a model similar to the one I used in the last challenge. It's been adapted for sequence tagging and achieved just under 99% validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment variables. **Set `train_file` and `test_file` to the relative filepaths of the data.** If `test_file` is an empty string no test data will be used.\n",
    "The validation split determines the percentage of training samples set aside for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_file = \"data/train.tsv\"\n",
    "test_file = \"\"\n",
    "val_split = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set random seed for reproducability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the `TEXT` and `TAG` fields. Set all `TEXT` tokens to lowercase for normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/student/rolwesg/.local/lib/python3.7/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "TEXT = data.Field(lower = True)\n",
    "TAGS = data.Field(unk_token = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fields = ((\"text\", TEXT), (\"tags\", TAGS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an adapted version of the `SequenceTaggingDataset` from torchtext. Their implementation expected a specific data format that did not match the provided file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SequenceTaggingDataset(data.Dataset):\n",
    "    @staticmethod\n",
    "    def sort_key(example):\n",
    "        for attr in dir(example):\n",
    "            if not callable(getattr(example, attr)) and \\\n",
    "                    not attr.startswith(\"__\"):\n",
    "                return len(getattr(example, attr))\n",
    "        return 0\n",
    "\n",
    "    def __init__(self, path, fields, encoding=\"utf-8\", separator=\"\\t\", **kwargs):\n",
    "        print(\"Loading data...\")\n",
    "        examples = []\n",
    "        columns = []\n",
    "\n",
    "        with open(path, encoding=encoding) as input_file:\n",
    "            for line in input_file:\n",
    "                line = line.strip()\n",
    "                if line.split(separator)[0] == \"<S>\":\n",
    "                    if columns:\n",
    "                        examples.append(data.Example.fromlist(columns, fields))\n",
    "                    columns = []\n",
    "                else:\n",
    "                    for i, column in enumerate(line.split(separator)):\n",
    "                        if len(columns) < i + 1:\n",
    "                            columns.append([])\n",
    "                        columns[i].append(column)\n",
    "            if columns:\n",
    "                examples.append(data.Example.fromlist(columns, fields))\n",
    "        print(\"Data loaded from {}\".format(path))\n",
    "        super(SequenceTaggingDataset, self).__init__(examples, fields,\n",
    "                                                     **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data into a Pytorch dataset and split based on the provided `val_split`. Load the test dataset if one is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/student/rolwesg/.local/lib/python3.7/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from data/train.tsv\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = SequenceTaggingDataset(train_file, fields).split(split_ratio=1-val_split)\n",
    "if len(test_file) > 0:\n",
    "    test_data = SequenceTaggingDataset(test_file, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 277145\n",
      "Training samples: 118777\n",
      "Testing samples: 277145\n"
     ]
    }
   ],
   "source": [
    "print(\"Training samples: {}\".format(len(train_data)))\n",
    "print(\"Validation samples: {}\".format(len(val_data)))\n",
    "if \"test_data\" in globals():\n",
    "    print(\"Testing samples: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['is', 'dócha', 'gur', 'cuala', 'gach', 'duine', 'againn', 'moltaí', 'ag', 'teacht', 'ó', 'comhairlí', 'contae', 'gur', 'féidir', 'gearradh', 'siar', 'de', '<num>', '%', 'ar', 'an', 'méid', 'dramhaíola', 'taobh', 'istigh', 'de', 'roinnt', 'blianta', '.'], 'tags': ['N', 'N', 'N', 'S', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'S', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'N', 'S', 'N', 'N', 'N', 'N', 'N', 'N', 'N']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the vocab. I'm only including words that appear twice or more in the embeddings. Any unseen words or words with only one occurrence will be judged solely on the surrounding tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MIN_FREQ = 2\n",
    "\n",
    "TEXT.build_vocab(train_data,\n",
    "                 min_freq = MIN_FREQ)\n",
    "TAGS.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT: 61602\n",
      "Unique tokens in TAG: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique tokens in TEXT: {}\".format(len(TEXT.vocab)))\n",
    "print(\"Unique tokens in TAG: {}\".format(len(TAGS.vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the batch size and the GPU if one is available. **I was only able to run this in a reasonable amount of time using a GPU**.\n",
    "Then create the iterators to produce batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/student/rolwesg/.local/lib/python3.7/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "train_iterator, val_iterator = data.BucketIterator.splits(\n",
    "    (train_data, val_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device\n",
    ")\n",
    "if \"test_data\" in globals():\n",
    "    test_iterator = data.BucketIterator(test_data, batch_size = BATCH_SIZE, device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare the model class.Similar setup to last time: embedding layer followed by LSTM with bidirectional support and the option to add multiple layers. Then a linear layer to produce outputs with dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class POSTagger(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout,\n",
    "                 pad_idx):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_idx)\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim,\n",
    "                            num_layers = n_layers,\n",
    "                            bidirectional = bidirectional,\n",
    "                            dropout = dropout if n_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        outputs, (hidden, cell) = self.lstm(embedded)\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to last time, I used 100-dimension embeddings along with 2 bidirectional LSTM layers. The output dimension has to be the number of tags since we're deciding between mutliple tags, unlike last time where it was a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(TAGS.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.3\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = POSTagger(INPUT_DIM,\n",
    "                        EMBEDDING_DIM,\n",
    "                        HIDDEN_DIM,\n",
    "                        OUTPUT_DIM,\n",
    "                        N_LAYERS,\n",
    "                        BIDIRECTIONAL,\n",
    "                        DROPOUT,\n",
    "                        PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I'm not using pretrained weights this time, initialize the embedding weights to have a Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSTagger(\n",
       "  (embedding): Embedding(61602, 100, padding_idx=1)\n",
       "  (lstm): LSTM(100, 128, num_layers=2, dropout=0.3, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=6, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print trainable parameters to judge size of the model. It's fairly large, which explains the GPU requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6792526 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"{} trainable parameters\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set weights for padding to zero to ignore their affect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0214, -0.1501, -0.0780,  ..., -0.1113,  0.1239, -0.0879],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0490, -0.1034, -0.1875,  ..., -0.0086, -0.1052,  0.1024],\n",
      "        ...,\n",
      "        [ 0.1334,  0.1853,  0.0196,  ..., -0.0059, -0.0565, -0.0670],\n",
      "        [ 0.0093, -0.0242,  0.1470,  ..., -0.0858, -0.0875,  0.0155],\n",
      "        [ 0.0475,  0.1175, -0.0679,  ..., -0.1348,  0.1007, -0.1227]])\n"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard Adam optimizer with self-generated learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like last time, `CrossEntropyLoss`, but this time I had to ignore any outputs from padding tags since every word has an output, not just the whole sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "TAG_PAD_IDX = TAGS.vocab.stoi[TAGS.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the model and loss to the GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine accuracy. This was pretty much a copy and paste from [this repo](https://github.com/bentrevett/pytorch-pos-tagging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True)\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard train and eval functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        text = batch.text\n",
    "        tags = batch.tags\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        predictions = model(text.to(device))\n",
    "\n",
    "        # reshape predictions since pytorch can't handle 3-dimensional predictions\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "\n",
    "        loss = criterion(predictions, tags.to(device))\n",
    "\n",
    "        acc = categorical_accuracy(predictions.cpu(), tags.cpu(), tag_pad_idx)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch.text\n",
    "            tags = batch.tags\n",
    "\n",
    "            predictions = model(text.to(device))\n",
    "\n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "\n",
    "            loss = criterion(predictions, tags.to(device))\n",
    "            acc = categorical_accuracy(predictions.cpu(), tags.cpu(), tag_pad_idx)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/student/rolwesg/.local/lib/python3.7/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss: 0.142 | Train Acc: 0.954\n",
      "Val Loss: 0.086 | Val Acc: 0.971\n",
      "Epoch: 2\n",
      "Train Loss: 0.078 | Train Acc: 0.974\n",
      "Val Loss: 0.075 | Val Acc: 0.975\n",
      "Epoch: 3\n",
      "Train Loss: 0.066 | Train Acc: 0.978\n",
      "Val Loss: 0.072 | Val Acc: 0.977\n",
      "Epoch: 4\n",
      "Train Loss: 0.059 | Train Acc: 0.980\n",
      "Val Loss: 0.068 | Val Acc: 0.978\n",
      "Epoch: 5\n",
      "Train Loss: 0.054 | Train Acc: 0.982\n",
      "Val Loss: 0.068 | Val Acc: 0.978\n",
      "Epoch: 6\n",
      "Train Loss: 0.051 | Train Acc: 0.983\n",
      "Val Loss: 0.069 | Val Acc: 0.978\n",
      "Epoch: 7\n",
      "Train Loss: 0.048 | Train Acc: 0.984\n",
      "Val Loss: 0.070 | Val Acc: 0.978\n",
      "Epoch: 8\n",
      "Train Loss: 0.045 | Train Acc: 0.985\n",
      "Val Loss: 0.071 | Val Acc: 0.978\n",
      "Epoch: 9\n",
      "Train Loss: 0.043 | Train Acc: 0.986\n",
      "Val Loss: 0.073 | Val Acc: 0.979\n",
      "Epoch: 10\n",
      "Train Loss: 0.041 | Train Acc: 0.986\n",
      "Val Loss: 0.075 | Val Acc: 0.978\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    val_loss, val_acc = evaluate(model, val_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "\n",
    "    print(\"Epoch: {}\".format(epoch+1))\n",
    "    print(f\"Train Loss: {train_loss:.3f} | Train Acc: {train_acc:.3f}\")\n",
    "    print(f\"Val Loss: {val_loss:.3f} | Val Acc: {val_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "I was surprised at how well this was able to do with largely out of the box torchtext. The library certainly has a steep learning curve but I'm seeing its capabilities. I was able to get just below a 99% validation accuracy after a few epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"test_data\" in globals():\n",
    "    model.load_state_dict(torch.load('model.pt'))\n",
    "\n",
    "    test_loss, test_data = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.3f} | Test Acc: {val_acc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
